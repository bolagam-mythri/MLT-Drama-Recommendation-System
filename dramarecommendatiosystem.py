# -*- coding: utf-8 -*-
"""DramaRecommendatioSystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TWaDVnIhhYc2W9Jj4Je-SHNC6MUl5c0s
"""

# Install dependencies
!pip install sentence-transformers textblob

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from textblob import TextBlob
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

from google.colab import files
uploaded = files.upload()   # select the file you downloaded, e.g. "kdrama.csv"

import pandas as pd
df = pd.read_csv("kdrama_DATASET.csv")   # use the exact filename shown after upload
print(df.shape)
print(df.columns)
df.head()

# Flexible column mapping: rename to a standard schema if present
col_map_candidates = {
    'title': ['Title', 'title', 'Drama_Name', 'Drama Name', 'Name'],
    'year': ['Year', 'Released Year', 'year', 'Release Year'],
    'episodes': ['Episodes', 'Episode', 'episodes'],
    'rating': ['Rating', 'Score', 'rating'],
    'description': ['Description', 'Plot', 'Synopsis', 'description'],
    'genre': ['Genre', 'Genres', 'genre'],
    'language': ['Language', 'Lang', 'language', 'Country']  # fallback to Country if Language missing
}

def pick_col(df, candidates, default=None):
    for c in candidates:
        if c in df.columns:
            return c
    return default

std_cols = {k: pick_col(df, v) for k, v in col_map_candidates.items()}

# Create a clean dataframe with standardized names
df_clean = pd.DataFrame({
    'title': df[std_cols['title']] if std_cols['title'] else df.iloc[:,0],
    'year': df[std_cols['year']] if std_cols['year'] else np.nan,
    'episodes': df[std_cols['episodes']] if std_cols['episodes'] else np.nan,
    'rating': df[std_cols['rating']] if std_cols['rating'] else np.nan,
    'description': df[std_cols['description']] if std_cols['description'] else "",
    'genre': df[std_cols['genre']] if std_cols['genre'] else "",
    'language': df[std_cols['language']] if std_cols['language'] else ""
})

# Basic cleaning
for c in ['title', 'description', 'genre', 'language']:
    df_clean[c] = df_clean[c].fillna("").astype(str).str.strip()

for c in ['year', 'episodes', 'rating']:
    df_clean[c] = pd.to_numeric(df_clean[c], errors='coerce')

df = df_clean.drop_duplicates(subset=['title']).reset_index(drop=True)
print("Normalized columns:", df.columns.tolist())
df.head()

plt.figure(figsize=(12,4))
df['year'].dropna().value_counts().sort_index().plot(kind='line', color='tomato')
plt.title("Release trend over years")
plt.show()

plt.figure(figsize=(10,4))
df.groupby('language')['rating'].mean().sort_values(ascending=False).head(10).plot(kind='bar', color='steelblue')
plt.title("Average ratings by language")
plt.show()

plt.figure(figsize=(10,4))
df['genre'].str.split(',').explode().str.strip().value_counts().head(15).plot(kind='bar', color='seagreen')
plt.title("Top genres")
plt.show()

# Sentiment polarity on description
def get_sentiment_label(text):
    p = TextBlob(text).sentiment.polarity
    if p > 0.2: return "positive"
    if p < -0.2: return "negative"
    return "neutral"

df['sentiment'] = df['description'].apply(get_sentiment_label)

# Unified text feature: genre + description + language + sentiment
df['features_text'] = (
    df['genre'].fillna("") + " | " +
    df['language'].fillna("") + " | " +
    df['sentiment'].fillna("") + " | " +
    df['description'].fillna("")
)

# Multilingual semantic embeddings (much stronger than TF-IDF)
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embeddings = model.encode(df['features_text'].tolist(), convert_to_numpy=True, normalize_embeddings=True)

# Cosine similarity matrix
sim_matrix = cosine_similarity(embeddings, embeddings)

def recommend_titles(title, df, sim_matrix, top_k=10):
    # Look up index safely
    matches = df.index[df['title'].str.lower() == title.lower()].tolist()
    if not matches:
        return []
    idx = matches[0]

    scores = list(enumerate(sim_matrix[idx]))
    scores = sorted(scores, key=lambda x: x[1], reverse=True)

    recs = []
    for j, s in scores[1:top_k+1]:
        recs.append({'title': df.iloc[j]['title'], 'score': float(s)})
    return recs

# Example
seed = "The Tale of Nokdu"  # change as you like
recs = recommend_titles(seed, df, sim_matrix, top_k=10)
recs[:5]

# Overlap-based metrics
def precision_at_k(recommended_titles, relevant_titles, k=5):
    rec_at_k = [r['title'] for r in recommended_titles[:k]]
    hits = len(set(rec_at_k) & set(relevant_titles))
    return hits / max(k, 1)

def recall_at_k(recommended_titles, relevant_titles, k=5):
    rec_at_k = [r['title'] for r in recommended_titles[:k]]
    hits = len(set(rec_at_k) & set(relevant_titles))
    return hits / max(len(relevant_titles), 1)

def ndcg_at_k(recommended_titles, relevant_titles, k=5):
    rec_at_k = [r['title'] for r in recommended_titles[:k]]
    dcg = 0.0
    for i, t in enumerate(rec_at_k):
        if t in relevant_titles:
            dcg += 1.0 / np.log2(i + 2)
    idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(relevant_titles), k)))
    return (dcg / idcg) if idcg > 0 else 0.0

# Helper: auto-generate a plausible relevant set from genre + language
def auto_relevant_set(seed_title, df, max_size=10):
    row = df[df['title'].str.lower() == seed_title.lower()]
    if row.empty:
        return []
    g = set([x.strip().lower() for x in row.iloc[0]['genre'].split(',') if x.strip()])
    lang = row.iloc[0]['language'].strip().lower()

    candidates = df[
        (df['language'].str.lower().str.strip() == lang) &
        (df['title'].str.lower() != seed_title.lower())
    ].copy()

    def genre_overlap(genres):
        gg = set([x.strip().lower() for x in str(genres).split(',') if x.strip()])
        return len(g & gg)

    candidates['genre_overlap'] = candidates['genre'].apply(genre_overlap)
    relevant = candidates.sort_values(['genre_overlap', 'rating'], ascending=[False, False]).head(max_size)['title'].tolist()
    return relevant

# Dashboard: prints multiple metrics
def evaluate_title(seed_title, df, sim_matrix, k=5):
    recommended = recommend_titles(seed_title, df, sim_matrix, top_k=max(10,k))
    relevant = auto_relevant_set(seed_title, df, max_size=10)

    p = precision_at_k(recommended, relevant, k)
    r = recall_at_k(recommended, relevant, k)
    n = ndcg_at_k(recommended, relevant, k)

    # Coverage: across a sample of seeds
    sample_seeds = df['title'].head(50).tolist()
    all_recs = []
    for s in sample_seeds:
        all_recs += [x['title'] for x in recommend_titles(s, df, sim_matrix, top_k=5)]
    coverage = len(set(all_recs)) / len(df)

    # Diversity: average pairwise dissimilarity in the recommendation list
    idxs = []
    titles_in_rec = [x['title'] for x in recommended[:k]]
    for t in titles_in_rec:
        m = df.index[df['title'].str.lower() == t.lower()].tolist()
        if m: idxs.append(m[0])
    if len(idxs) > 1:
        sims = []
        for i in range(len(idxs)):
            for j in range(i+1, len(idxs)):
                sims.append(sim_matrix[idxs[i], idxs[j]])
        diversity = 1 - (np.mean(sims) if sims else 1.0)
    else:
        diversity = 0.0

    # Novelty: recommend less-popular (proxy: lower mean rating rank by quantile)
    # If rating missing for some rows, treat as mid-range
    ratings = []
    for t in titles_in_rec:
        rr = df.loc[df['title'].str.lower() == t.lower(), 'rating']
        ratings.append(rr.iloc[0] if len(rr) else np.nan)
    ratings = pd.Series(ratings, dtype=float)
    novelty = 1 - ratings.rank(pct=True).mean() if len(ratings) else 0.0

    print(f"Seed: {seed_title}")
    print(f"Recommended (top {k}): {[x['title'] for x in recommended[:k]]}")
    print(f"Auto relevant set (size {len(relevant)}): {relevant}")
    print(f"Precision@{k}: {p:.3f}")
    print(f"Recall@{k}: {r:.3f}")
    print(f"NDCG@{k}: {n:.3f}")
    print(f"Coverage (sample 50 seeds): {coverage:.3f}")
    print(f"Diversity (1 - avg similarity): {diversity:.3f}")
    print(f"Novelty (1 - avg rating percentile): {novelty:.3f}")

# Example evaluation
evaluate_title("The Tale of Nokdu", df, sim_matrix, k=5)

import ipywidgets as widgets
from IPython.display import display

titles = sorted(df['title'].unique().tolist())[:500]  # cap for dropdown

dropdown = widgets.Dropdown(options=titles, description='Pick a drama:', layout=widgets.Layout(width='60%'))
out = widgets.Output()

def on_change(change):
    if change['name'] == 'value' and change['new']:
        out.clear_output()
        with out:
            evaluate_title(change['new'], df, sim_matrix, k=5)

dropdown.observe(on_change, names='value')
display(dropdown, out)